# Spot Human Gesture Recognition

## Introduction

This project aims to create a robust framework for human interaction with BostonDynamics Spot robot. The framework is based on the MediaPipe pose estimation model and XMem object tracking models. With those models, a ground truth of the human pose is created and used to train a custom gesture recognition model. The gesture recognition model is then used to control the Spot robot. The framework is designed to be modular and can be easily extended to other tasks.

## Installation

Mamba Environment:
TODO

XMem:
TODO

MediaPipe:
TODO
